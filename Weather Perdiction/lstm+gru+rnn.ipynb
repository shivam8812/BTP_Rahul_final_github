{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MGEaA6ggpoza"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import urllib.request\n",
        "import matplotlib.dates as mdates\n",
        "import datetime as Date\n",
        "from geopy.geocoders import Nominatim\n",
        "pd.set_option('display.max_columns',None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "\n",
        "url = \"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=T2M_MAX,T2M_MIN,RH2M,PRECTOTCORR,PS,WS50M_MAX,WS50M_MIN&community=RE&longitude=71.4000&latitude=19.2000&start=20050101&end=20221231&format=CSV\"\n",
        "# Assuming the dataset is in a CSV file with columns: date, param1, param2, ..., param7\n",
        "\n",
        "urllib.request.urlretrieve(url,'climate.csv')\n",
        "df = pd.read_csv('climate.csv',skiprows = 15)\n",
        "\n",
        "df['YEAR'] = df.YEAR.astype(str)\n",
        "df['MO'] = df.MO.astype(str)\n",
        "df['DY'] = df.DY.astype(str)\n",
        "\n",
        "df['date'] = df['YEAR'].str.cat(df['MO'],sep = '/')\n",
        "df['DATE'] = df['date'].str.cat(df['DY'],sep = '/')\n",
        "df.drop(columns = ['YEAR','MO','DY','date','DATE'],axis=1,inplace=True)\n",
        "\n",
        "# Normalize the data using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df.values)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "data = torch.from_numpy(df_scaled).float()"
      ],
      "metadata": {
        "id": "JkzqG4d3s2k1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "WpKNDVJ5tJH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e7a638-0be6-4b53-cc4f-31deee9b5404"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6574, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn1 = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.rnn2 = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.rnn3 = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru3 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout3 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.rnn4 = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.gru4 = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.bn4 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout4 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        hidden1_rnn = self.init_hidden(batch_size)\n",
        "        hidden2_rnn = self.init_hidden(batch_size)\n",
        "        hidden3_rnn = self.init_hidden(batch_size)\n",
        "        hidden4_rnn = self.init_hidden(batch_size)\n",
        "        \n",
        "       \n",
        "\n",
        "        \n",
        "\n",
        "        out_lstm1,_ = self.lstm1(x)\n",
        "        out_gru1,_= self.gru1(out_lstm1)\n",
        "\n",
        "        out_lstm2, _ = self.lstm2(out_gru1)\n",
        "        out_gru2, _ = self.gru2(out_lstm2)\n",
        "        \n",
        "        \n",
        "\n",
        "        out_rnn1, hidden1_rnn = self.rnn1(out_gru2, hidden1_rnn)\n",
        "        out_rnn2, hidden2_rnn = self.rnn2(out_rnn1, hidden2_rnn)\n",
        "        out_rnn3, hidden3_rnn = self.rnn3(out_rnn2, hidden3_rnn)\n",
        "        out_rnn4, hidden4_rnn = self.rnn4(out_rnn3, hidden4_rnn)\n",
        "\n",
        "        out = self.fc(out_rnn4[:, -1:, :])\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, self.hidden_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "K7RwaQ-usiUo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize hyperparameters\n",
        "input_size = 7  # 7 weather parameters\n",
        "hidden_size = 64   # specify your desired hidden size\n",
        "num_layers = 2     # specify your desired number of layers\n",
        "output_size = 7   # 7 weather parameters x 7 days\n",
        "seq_length = 15  # Number of previous days to consider as input\n",
        "target_length = 1 # Number of future days to consider as output\n",
        "batch_size = 32  # Batch size for training\n",
        "learning_rate = 0.001  # Learning rate for optimizer\n",
        "num_epochs = 50  # Number of epochs for training\n",
        "\n"
      ],
      "metadata": {
        "id": "aFFci7S0tARY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input sequences and targets for predicting the next 7 days\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(data) - seq_length - target_length):\n",
        "    seq = data[i:i + seq_length, :]\n",
        "    target = data[i + seq_length:i + seq_length + target_length, :]\n",
        "    X.append(seq)\n",
        "    y.append(target)\n",
        "X = torch.stack(X)\n",
        "y = torch.stack(y)\n",
        "\n",
        "# Calculate sizes for train, validation, and test sets\n",
        "train_size = int(0.7 * len(X))\n",
        "val_size = int(0.15 * len(X))\n",
        "test_size = len(X) - train_size - val_size\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_X, val_X, test_X = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\n",
        "train_y, val_y, test_y = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(val_X.shape)\n",
        "print(val_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)\n",
        "\n",
        "# Create DataLoader for training set\n",
        "train_dataset = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create DataLoader for validation set\n",
        "val_dataset = torch.utils.data.TensorDataset(val_X, val_y)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create DataLoader for test set\n",
        "test_dataset = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Ggo9sl0UJAS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a670ed-b0f8-4186-8790-ae5be07bd483"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4590, 15, 7])\n",
            "torch.Size([4590, 1, 7])\n",
            "torch.Size([983, 15, 7])\n",
            "torch.Size([983, 1, 7])\n",
            "torch.Size([985, 15, 7])\n",
            "torch.Size([985, 1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "# Create an instance of the hybrid model\n",
        "model = HybridModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean squared error loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "train_losses = []  # List to store training losses for each epoch\n",
        "val_losses = []  # List to store validation losses for each epoch\n",
        "best_loss = float('inf')  # Set initial best loss to positive infinity\n",
        "best_model_state_dict = None  # Variable to store the state_dict of the best model\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_train_loss = 0.0\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    model.eval()\n",
        "    epoch_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            epoch_val_loss += criterion(outputs, targets).item()\n",
        "    epoch_val_loss /= len(val_loader)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "\n",
        "    # Update the best model if the current model has a lower validation loss\n",
        "    if epoch_val_loss < best_loss:\n",
        "        best_loss = epoch_val_loss\n",
        "        best_model_state_dict = model.state_dict()\n",
        "        torch.save(best_model_state_dict, 'best_model.pth')  # Save the best model to a file\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
        "\n",
        "# Plot the training and validation loss graphs\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'Training complete. Best model saved with validation loss: {best_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "CcyzNgdVtEn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "# Load the saved state_dict of the best model\n",
        "best_model_state_dict = torch.load('best_model.pth')\n",
        "\n",
        "# Set the model's state_dict to the loaded state_dict\n",
        "model.load_state_dict(best_model_state_dict)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_X)\n",
        "    test_loss = criterion(test_outputs, test_y)\n",
        "print('Test Loss: {:.4f}'.format(test_loss.item()))"
      ],
      "metadata": {
        "id": "slEOa7MNuIid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecda7d87-1faa-4e66-ac95-00330b81ae72"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted = model(test_X)\n",
        "\n",
        "# # # Denormalize the predicted values\n",
        "# denormalized_tensor = scaler.inverse_transform(predicted.view(-1, 7)).view(580, 7, 7)\n",
        "# denormalized_tensor_y = scaler.inverse_transform(test_y.view(-1, 7)).view(580, 7, 7)\n",
        "# predicted.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "qSOTAQVXzyFq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denormalized_tensor = torch.empty_like(predicted)\n",
        "denormalized_tensor_y = torch.empty_like(test_y)\n",
        "for i in range(predicted.shape[0]):\n",
        "    for j in  range(0,1):\n",
        "      num = predicted[i][j].numpy()\n",
        "      nump = np.array(num)\n",
        "      numpp = nump.reshape(1,7)\n",
        "      denorm = scaler.inverse_transform(numpp)\n",
        "      denormm = torch.from_numpy(denorm)\n",
        "      denormalized_tensor[i][j] = denormm\n",
        "for i in range(test_y.shape[0]):\n",
        "    for j in  range(0,1):\n",
        "      num = test_y[i][j].numpy()\n",
        "      nump = np.array(num)\n",
        "      numpp = nump.reshape(1,7)\n",
        "      denorm = scaler.inverse_transform(numpp)\n",
        "      denormm = torch.from_numpy(denorm)\n",
        "      denormalized_tensor_y[i][j] = denormm\n",
        "for i in range(0,10):\n",
        "  print(denormalized_tensor[i])\n",
        "  print(\"/////\")\n",
        "  print(denormalized_tensor_y[i])\n",
        "  print(\"//////////////////////////////////////////////////////////////////////////\")"
      ],
      "metadata": {
        "id": "2s3Z6nbW5WoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Create a new figure and set its size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the i-th column of denormalized_tensor and denormalized_tensor_y\n",
        "plt.plot(denormalized_tensor_y[:, 0], label='Actual')\n",
        "plt.plot(denormalized_tensor[:, 0], label='Predicted')\n",
        "\n",
        "\n",
        "# Set plot title and axis labels\n",
        "plt.xlabel('Index',fontsize = 18)\n",
        "plt.ylabel('Value',fontsize = 18)\n",
        "\n",
        "# Show legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gfbn5tX0Bwst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6) \n",
        "\n",
        "\n",
        "# Plot the i-th column of denormalized_tensor and denormalized_tensor_y\n",
        "plt.plot(denormalized_tensor_y[:,0], label='Actual')\n",
        "plt.plot(denormalized_tensor[:, 0], label='Predicted')\n",
        "\n",
        "\n",
        "# Set plot title and axis labels\n",
        "plt.xlabel('Index',fontsize = 18)\n",
        "plt.ylabel('Value',fontsize = 18)\n",
        "\n",
        "# Show legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PIM0Bhw9AMVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(denormalized_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOzpC3l1AslS",
        "outputId": "814f1dc6-3f9b-452d-e43a-871a575c5d72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([985, 1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denormalized_tensor = denormalized_tensor.reshape([985,7])"
      ],
      "metadata": {
        "id": "6zfmeV6eA-B8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denormalized_tensor_y = denormalized_tensor_y.reshape([985,7])"
      ],
      "metadata": {
        "id": "Gy6LOVotBdUd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6) \n",
        "\n",
        "\n",
        "# Plot the i-th column of denormalized_tensor and denormalized_tensor_y\n",
        "plt.plot(denormalized_tensor_y[:,3], label='Actual')\n",
        "plt.plot(denormalized_tensor[:, 3], label='Predicted')\n",
        "\n",
        "\n",
        "# Set plot title and axis labels\n",
        "plt.xlabel('Index',fontsize = 18)\n",
        "plt.ylabel('Value',fontsize = 18)\n",
        "plt.xticks(fontsize = 16)\n",
        "plt.yticks(fontsize = 16)\n",
        "# Show legend\n",
        "plt.legend(fontsize = 18)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bM-nUPR1Bgv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(denormalized_tensor.shape)"
      ],
      "metadata": {
        "id": "f_X1pejKBsVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}